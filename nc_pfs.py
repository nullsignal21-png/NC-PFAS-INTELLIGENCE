# -*- coding: utf-8 -*-
"""NC_PFS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tkb4HuMvDiQMatwOPK5chOnir0bSVjs3
"""

!pip install tabula-py camelot-py[cv] plotly folium jpype1

import pandas as pd
import tabula
import camelot
import plotly.express as px
import folium
import json
import requests
from io import BytesIO


MCL_THRESHOLDS = {
    'PFOA': 4,
    'PFOS': 4,
    'GenX (HFPO-DA)': 10,
    'PFNA': 10,
    'PFHxS': 10,
    'PFBS': 2000
}


HEALTH_INFO = {
    'Low': 'Below EPA drinking water limits.',
    'Medium': 'Near or slightly above EPA limits. Consider testing and filtration.',
    'High': 'Above EPA limits. Filtration and reporting strongly recommended.'
}


def risk_level(value, mcl):
    if pd.isna(value) or value < mcl:
        return 'Low'
    elif value < 2 * mcl:
        return 'Medium'
    else:
        return 'High'

url_a = 'https://www.deq.nc.gov/water-resources/pws/2023-public-water-system-sampling-data-table/download'
response_a = requests.get(url_a)
pdf_a = BytesIO(response_a.content)


tables_a = tabula.read_pdf(pdf_a, pages='all', multiple_tables=True)
df_a = pd.concat(tables_a, ignore_index=True) if tables_a else pd.DataFrame()
df_a.to_csv('dataset_a_raw.csv', index=False)


url_b = 'https://www.deq.nc.gov/key-issues/2022-pfas-data-pfoa-pfospdf/download'
response_b = requests.get(url_b)
pdf_b = BytesIO(response_b.content)

tables_b = tabula.read_pdf(pdf_b, pages='all', multiple_tables=True)
df_b = pd.concat(tables_b, ignore_index=True) if tables_b else pd.DataFrame()
df_b.to_csv('dataset_b_raw.csv', index=False)

# Dataset C: EPA UCMR 5 (LOCAL FILE, NO URL)

ucmr5_path = "UCMR5_All_MA_WY.txt"

df_c = pd.read_csv(
    ucmr5_path,
    sep='\t',
    low_memory=False,
    encoding='latin1'
)


df_c = df_c.rename(columns={
    'PWSName': 'system_name',
    'CollectionDate': 'sample_date',
    'Contaminant': 'pfas_type',
    'AnalyticalResultValue': 'concentration_ppt'
})


if 'county' not in df_c.columns:
    df_c['county'] = None


df_c['year'] = 2023


df_c = df_c[df_c['pfas_type'].isin(MCL_THRESHOLDS.keys())]


df_c = df_c[
    ['system_name', 'county', 'sample_date', 'pfas_type', 'concentration_ppt', 'year']
]

print("UCMR 5 loaded:", df_c.shape)

# Cell 3: STEP 2 — CLEAN & STANDARDIZE (AUTO-DETECT VERSION)

import pandas as pd


df_a = pd.read_csv('dataset_a_raw.csv')
df_b = pd.read_csv('dataset_b_raw.csv')

def normalize_cols(df):
    df.columns = (
        df.columns
        .str.strip()
        .str.lower()
        .str.replace('\n', ' ')
        .str.replace(r'\s+', ' ', regex=True)
    )
    return df

df_a = normalize_cols(df_a)
df_b = normalize_cols(df_b)


df_a['year'] = 2023
df_b['year'] = 2022



def rename_key_columns_before_concat(df):
    df_copy = df.copy()


    system_col = next(
        (c for c in df_copy.columns if 'system' in c and 'name' in c),
        None
    )
    if system_col and system_col != 'system_name':
        df_copy = df_copy.rename(columns={system_col: 'system_name'})
    if 'system_name' not in df_copy.columns:
        df_copy['system_name'] = None


    county_col = next(
        (c for c in df_copy.columns if 'county' in c),
        None
    )
    if county_col and county_col != 'county':
        df_copy = df_copy.rename(columns={county_col: 'county'})

    if 'county' not in df_copy.columns:
        df_copy['county'] = None


    date_col = next(
        (c for c in df_copy.columns if 'date' in c),
        None
    )
    if date_col and date_col != 'sample_date':
        df_copy = df_copy.rename(columns={date_col: 'sample_date'})

    if 'sample_date' not in df_copy.columns:
        df_copy['sample_date'] = None

    return df_copy

df_a = rename_key_columns_before_concat(df_a)
df_b = rename_key_columns_before_concat(df_b)




df_combined = pd.concat([df_a, df_b, df_c], ignore_index=True, sort=False)



# ---- STANDARDIZE PFAS COLUMN NAMES ----
pfas_map = {}
for col in df_combined.columns:
    if 'pfos' in col:
        pfas_map[col] = 'PFOS'
    elif 'pfoa' in col:
        pfas_map[col] = 'PFOA'
    elif 'genx' in col or 'hfpo' in col:
        pfas_map[col] = 'GenX (HFPO-DA)'
    elif 'pfna' in col:
        pfas_map[col] = 'PFNA'
    elif 'pfhxs' in col:
        pfas_map[col] = 'PFHxS'
    elif 'pfbs' in col:
        pfas_map[col] = 'PFBS'

df_combined = df_combined.rename(columns=pfas_map)


df_combined['system_id'] = (
    df_combined['system_name']
    .astype(str)
    .str.extract(r'(\d{6,7})')
)


if 'concentration_ppt' in df_combined.columns:
    df_combined = df_combined.drop(columns=['concentration_ppt'])


actual_pfas_columns = [col for col in pfas_map.values() if col in df_combined.columns]


id_vars_for_melt = [col for col in ['system_id', 'system_name', 'county', 'sample_date', 'year'] if col in df_combined.columns]

df_long = df_combined.melt(
    id_vars=id_vars_for_melt,
    value_vars=actual_pfas_columns,
    var_name='pfas_type',
    value_name='concentration_ppt'
)


df_long['concentration_ppt'] = (
    df_long['concentration_ppt']
    .replace(['ND', 'nd', 'Non-Detect', 'NON-DETECT'], None)
)

df_long['concentration_ppt'] = pd.to_numeric(
    df_long['concentration_ppt'],
    errors='coerce'
)

df_clean = df_long.dropna(subset=['pfas_type'])


print("✅ Data cleaned successfully")
print("Shape:", df_clean.shape)

df_clean.head()

# Cell 4: STEP 3 — AGGREGATE BY LOCATION


df_agg = df_clean.groupby(['county', 'pfas_type']).agg({'concentration_ppt': 'max'}).reset_index()
df_agg.rename(columns={'concentration_ppt': 'max_concentration_ppt'}, inplace=True)


df_county = df_agg.pivot(index='county', columns='pfas_type', values='max_concentration_ppt').reset_index()

print("Aggregated by county. Shape:", df_county.shape)
df_county.head()

# Cell 5: STEP 4 — RISK CATEGORIZATION LOGIC



for pfas in MCL_THRESHOLDS.keys():
    if pfas in df_county.columns:
        df_county[f'{pfas}_risk'] = df_county[pfas].apply(lambda x: risk_level(x, MCL_THRESHOLDS[pfas]))


risk_cols = [f'{pfas}_risk' for pfas in MCL_THRESHOLDS.keys() if f'{pfas}_risk' in df_county.columns]
df_county['overall_risk'] = df_county[risk_cols].apply(lambda row: max(row, key=lambda x: ['Low', 'Medium', 'High'].index(x) if x in ['Low', 'Medium', 'High'] else -1), axis=1)


df_county['health_info'] = df_county['overall_risk'].map(HEALTH_INFO)

print("Risks categorized.")


zip_url = 'https://raw.githubusercontent.com/scpike/us-state-county-zip/master/geo-data.csv'
zip_df = pd.read_csv(zip_url)
zip_df = zip_df[zip_df['state_abbr'] == 'NC']
zip_df['zipcode'] = zip_df['zipcode'].astype(str).str.zfill(5)


zip_df['county_upper'] = zip_df['county'].str.upper()
df_county['county_upper'] = df_county['county'].str.upper()


df_zip = pd.merge(
    zip_df[['zipcode', 'county_upper']],
    df_county[['county_upper', 'overall_risk', 'health_info']],
    on='county_upper',
    how='left'
)


df_zip['overall_risk'] = df_zip['overall_risk'].fillna('No Data')
df_zip['health_info'] = df_zip['health_info'].fillna('No PFAS data available for this county.')


df_zip = df_zip.drop(columns=['county_upper'])

print("Expanded to zip codes. Shape:", df_zip.shape)
print(df_zip.head())

import requests
from io import BytesIO


geojson_url = 'https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json'
response = requests.get(geojson_url)
us_counties_geojson = response.json()


nc_geojson_features = [f for f in us_counties_geojson['features'] if f['id'][:2] == '37']
nc_geojson = {"type": "FeatureCollection", "features": nc_geojson_features}


nc_county_fips_list = []
for feature in nc_geojson['features']:
    county_name_from_geojson = feature['properties']['NAME'].upper()
    fips_code = feature['id']
    nc_county_fips_list.append({'county': county_name_from_geojson, 'fips': fips_code})

all_nc_counties_df = pd.DataFrame(nc_county_fips_list)


df_county_temp = df_county.copy()


for pfas in MCL_THRESHOLDS.keys():
    if pfas in df_county_temp.columns:
        df_county_temp[f'{pfas}_risk'] = df_county_temp[pfas].apply(lambda x: risk_level(x, MCL_THRESHOLDS[pfas]))

risk_cols = [f'{pfas}_risk' for pfas in MCL_THRESHOLDS.keys() if f'{pfas}_risk' in df_county_temp.columns]
df_county_temp['overall_risk'] = df_county_temp[risk_cols].apply(lambda row: max(row, key=lambda x: ['Low', 'Medium', 'High'].index(x) if x in ['Low', 'Medium', 'High'] else -1), axis=1)
df_county_temp['health_info'] = df_county_temp['overall_risk'].map(HEALTH_INFO)


df_county_temp['county_upper'] = df_county_temp['county'].str.upper()


pfas_concentration_cols = [col for col in MCL_THRESHOLDS.keys() if col in df_county_temp.columns]
pfas_risk_cols = [f'{pfas}_risk' for pfas in MCL_THRESHOLDS.keys() if f'{pfas}_risk' in df_county_temp.columns]


df_county_full = pd.merge(
    all_nc_counties_df,
    df_county_temp[['county_upper', 'overall_risk', 'health_info'] + pfas_concentration_cols + pfas_risk_cols], # Right DataFrame: df_county with risk info
    left_on='county',
    right_on='county_upper',
    how='left'
)


df_county_full = df_county_full.drop(columns=['county_upper'])


df_county_full['overall_risk'] = df_county_full['overall_risk'].fillna('No Data')
df_county_full['health_info'] = df_county_full['health_info'].fillna('No PFAS data available.')


missing_fips_count = df_county_full['fips'].isnull().sum()
if missing_fips_count > 0:
    print(f"Warning: {missing_fips_count} counties in df_county_full could not be mapped to FIPS codes.")
    print("Counties with missing FIPS:", df_county_full[df_county_full['fips'].isnull()]['county'].unique())




df_county_full.to_csv('pfas_nc_clean.csv', index=False)


jason_data = []
for _, row in df_county_full.iterrows(): # Now iterating over df_county_full
    pfas_dict = {pfas: row[pfas] for pfas in MCL_THRESHOLDS.keys() if pfas in row and not pd.isna(row[pfas])}
    jason_data.append({
        'county': row['county'],
        'pfas': pfas_dict,
        'risk': row['overall_risk'],
        'health_info': row['health_info']
    })

with open('pfas_nc_clean.json', 'w') as f:
    json.dump(jason_data, f, indent=4)

print("Outputs saved: pfas_nc_clean.csv and pfas_nc_clean.json")



fig = px.choropleth(df_county_full,
                    geojson=nc_geojson,
                    locations='fips',
                    featureidkey="id",
                    color='overall_risk',
                    color_discrete_map={'Low': 'green', 'Medium': 'yellow', 'High': 'red', 'No Data': 'lightgray'},
                    scope='usa',
                    hover_name='county',
                    hover_data={'overall_risk': True, 'health_info': True, 'fips': False},
                    title='NC PFAS Risk by County (Including No Data Counties)'
                   )
fig.update_geos(fitbounds='locations', visible=False)
fig.show()

!pip install geopandas
import geopandas as gpd
import numpy as np
from branca.colormap import LinearColormap


geojson_zip_url = 'https://raw.githubusercontent.com/OpenDataDE/State-zip-code-GeoJSON/master/nc_north_carolina_zip_codes_geo.min.json'
response_zip = requests.get(geojson_zip_url)
with open('nc_zips.geojson', 'wb') as f:
    f.write(response_zip.content)


nc_zips_gdf = gpd.read_file('nc_zips.geojson')
nc_zips_gdf['zipcode'] = nc_zips_gdf['ZCTA5CE10'].astype(str).str.zfill(5)


df_zip['zipcode'] = df_zip['zipcode'].astype(str).str.zfill(5)
nc_zips_gdf = nc_zips_gdf.merge(df_zip[['zipcode', 'overall_risk', 'health_info']], on='zipcode', how='left')


nc_zips_gdf['overall_risk'] = nc_zips_gdf['overall_risk'].fillna('No Data')
nc_zips_gdf['health_info'] = nc_zips_gdf['health_info'].fillna('No PFAS data available.')


nc_zips_gdf['was_no_data'] = nc_zips_gdf['overall_risk'] == 'No Data'


def interpolate_risk(row):
    if row['overall_risk'] != 'No Data':
        return row['overall_risk']
    if row.geometry is None or not row.geometry.is_valid:
        return 'No Data'
    neighbors = nc_zips_gdf[
        (nc_zips_gdf.geometry.apply(lambda g: g.touches(row.geometry) if g and g.is_valid else False)) &
        (nc_zips_gdf['overall_risk'] != 'No Data')
    ]
    neighbor_risks = neighbors['overall_risk']
    if not neighbor_risks.empty:
        return neighbor_risks.mode()[0]
    return 'No Data'

nc_zips_gdf['overall_risk_interpolated'] = nc_zips_gdf.apply(interpolate_risk, axis=1)


nc_zips_gdf['centroid'] = nc_zips_gdf.geometry.centroid
zips_with_data = nc_zips_gdf[nc_zips_gdf['overall_risk'] != 'No Data'].copy()

def get_nearest_risk(row):
    if row['overall_risk'] != 'No Data':
        return row['overall_risk']
    if not zips_with_data.empty and row['centroid'] and row['centroid'].is_valid:
        distances = zips_with_data['centroid'].distance(row['centroid'])
        nearest_idx = distances.idxmin()
        nearest_risk = zips_with_data.loc[nearest_idx, 'overall_risk']
        return nearest_risk
    return 'No Data'

nc_zips_gdf['nearest_risk'] = nc_zips_gdf.apply(get_nearest_risk, axis=1)


def update_health_info(row):
    if not row['was_no_data']:
        return row['health_info']
    nearest = row['nearest_risk']
    if nearest != 'No Data':
        return f"This zip's risk is interpolated from neighbors. The nearest zip with data shows that you are most likely {nearest} risk."
    return "This zip's risk is interpolated from neighbors. No nearby zip has data available."

nc_zips_gdf['health_info_updated'] = nc_zips_gdf.apply(update_health_info, axis=1)


risk_to_numerical = {
    'No Data': -1,
    'Low': 0,
    'Medium': 1,
    'High': 2
}
nc_zips_gdf['overall_risk_num'] = nc_zips_gdf['overall_risk_interpolated'].map(risk_to_numerical)

risk_colors_map = {
    -1: '#D3D3D3',
    0: '#008000',
    1: '#FFFF00',
    2: '#FF0000'
}

colormap = LinearColormap(
    colors=[risk_colors_map[-1], risk_colors_map[0], risk_colors_map[1], risk_colors_map[2]],
    index=[-1, 0, 1, 2],
    vmin=-1,
    vmax=2,
    caption='PFAS Risk Level (Interpolated)'
)


m = folium.Map(location=[35.5, -79.0], zoom_start=7)

colormap.add_to(m)

for _, row in nc_zips_gdf.iterrows():
    if row['geometry'] and row['geometry'].is_valid:
        fill_color_for_feature = risk_colors_map.get(row['overall_risk_num'], '#D3D3D3')
        tooltip_text = f"Zip: {row['zipcode']}<br>Risk: {row['overall_risk_interpolated']}<br>Info: {row['health_info_updated']}"

        folium.GeoJson(
            row['geometry'],
            tooltip=tooltip_text,
            style_function=lambda x, fc=fill_color_for_feature: {
                'fillColor': fc,
                'color': 'black',
                'weight': 0.5,
                'fillOpacity': 0.7
            }
        ).add_to(m)




m.save('pfas_nc_zip_map.html')
print("Zip-level map with interpolation + nearest zip reference saved as pfas_nc_zip_map.html")
m

import json
import requests
import geopandas as gpd
from shapely.geometry import shape


county_geo_url = "https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json"
us_geo = requests.get(county_geo_url).json()

nc_features = [f for f in us_geo["features"] if f["id"].startswith("37")]
nc_geojson = {"type": "FeatureCollection", "features": nc_features}

county_rows = []
for f in nc_geojson["features"]:
    county_rows.append({
        "fips": f["id"],
        "geometry": shape(f["geometry"])
    })

county_gdf = gpd.GeoDataFrame(county_rows, crs="EPSG:4326")
county_gdf = county_gdf.merge(df_county_full, on="fips", how="left")


zip_geo_url = "https://raw.githubusercontent.com/OpenDataDE/State-zip-code-GeoJSON/master/nc_north_carolina_zip_codes_geo.min.json"
zip_geo = requests.get(zip_geo_url).json()

zip_gdf = gpd.GeoDataFrame.from_features(zip_geo["features"], crs="EPSG:4326")
zip_gdf["zipcode"] = zip_gdf["ZCTA5CE10"].astype(str).str.zfill(5)


zip_join = gpd.sjoin(
    zip_gdf,
    county_gdf,
    how="left",
    predicate="intersects"
)


risk_rank = {"Low": 0, "Medium": 1, "High": 2}

def worst_risk(vals):
    vals = vals.dropna()
    if vals.empty:
        return "No Data"
    return max(vals, key=lambda x: risk_rank.get(x, -1))

zip_final = (
    zip_join
    .groupby("zipcode")
    .agg({
        "overall_risk": worst_risk,
        "health_info": "first"
    })
    .reset_index()
)

zip_final["health_info"] = zip_final["health_info"].fillna(
    "No PFAS data available for this ZIP."
)


nc_hotspots = zip_final.to_dict(orient="records")

with open("pfas_nc_zip_clean.json", "w") as f:
    json.dump(nc_hotspots, f, indent=2)

print("Saved pfas_nc_zip_clean.json")

import sys
import subprocess
import os
import time
import threading
import json
import numpy as np
import requests
import folium

subprocess.run([sys.executable, "-m", "pip", "install", "--quiet",
                "streamlit==1.26", "plotly", "pandas", "numpy==1.26.4",
                "pyngrok", "geopandas", "branca", "folium", "streamlit-folium"])

from pyngrok import ngrok


NGROK_AUTH_TOKEN = "3925YGTEReJ5JxHst9V2r36dPes_4Pam4TcuWKixnqa4ifKFx"
ngrok.set_auth_token(NGROK_AUTH_TOKEN)


dashboard_code = r"""
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import json
import folium
from streamlit_folium import st_folium
import requests # Import requests inside the dashboard for GeoJSON download if needed
import geopandas as gpd # Import geopandas if needed for GeoJSON handling in dashboard

st.set_page_config(page_title="NC PFAS Intelligence", layout="wide")

# ----------------- CSS -----------------
st.markdown('''
<style>
.stApp {background: radial-gradient(circle at 50% 50%, #000c14 0%, #001a2e 40%, #000000 100%); color: #ffffff;}
.stApp::before { content: ""; position: fixed; top:0; left:0; width:100%; height:100%; background: radial-gradient(circle at 15% 15%, rgba(0,255,255,0.08) 0%, transparent 45%), radial-gradient(circle at 85% 85%, rgba(0,119,182,0.12) 0%, transparent 45%), repeating-linear-gradient(rgba(255,255,255,0.01) 0px, rgba(255,255,255,0.01) 1px, transparent 1px, transparent 20px); z-index: -1; animation: pulse 12s ease-in-out infinite alternate;}
@keyframes pulse {0% { transform: scale(1); opacity:0.6;} 100% { transform: scale(1.1); opacity:1;}}
.glass-card {background: rgba(255,255,255,0.03); backdrop-filter: blur(25px); -webkit-backdrop-filter: blur(25px); border: 1px solid rgba(0,180,216,0.2); border-radius: 30px; padding: 2.5rem; margin-bottom: 2rem; box-shadow: 0 20px 60px rgba(0,0,0,0.6);}
.nav-header {position: fixed; top:0; left:0; width:100%; height:65px; background: rgba(0,0,0,0.9); backdrop-filter: blur(15px); border-bottom: 2px solid #00b4d8; z-index:9999; display:flex; align-items:center; padding:0 40px;}
.block-container {padding-top: 6.5rem !important;}
#MainMenu, footer, header {visibility:hidden;}
::-webkit-scrollbar { width: 8px; } ::-webkit-scrollbar-track { background: #000c14; } ::-webkit-scrollbar-thumb { background: #00b4d8; border-radius: 10px; }
</style>
<div class="nav-header"><div style="font-size:24px; font-weight:900; color:#00b4d8; letter-spacing:-1px;">NC <span style="color:white">PFAS</span> MONITOR <span style="font-size:12px; font-weight:400; color:#48cae4; vertical-align:top; margin-left:10px;">PRO 2.7</span></div></div>
'''
, unsafe_allow_html=True)

# ----------------- DATA ENGINE -----------------
try:
    with open("pfas_nc_zip_clean.json", "r") as f:
        nc_hotspots_list = json.load(f)
    nc_hotspots = {item["zipcode"]: item["overall_risk"] for item in nc_hotspots_list}
    st.success(f"Loaded {len(nc_hotspots)} ZIP codes with PFAS risk info")
except FileNotFoundError:
    st.error("ZIP-level PFAS data file not found in this folder.")
    nc_hotspots = {}
except Exception as e:
    st.error(f"Error loading ZIP PFAS data: {e}")
    nc_hotspots = {}

# Example for nearest neighbor fallback
# Precompute nearest neighbor mapping if needed
zip_list = list(nc_hotspots.keys())
zip_risk_list = list(nc_hotspots.values())

# ----------------- TABS -----------------
tab1, tab2, tab3, tab4 = st.tabs([
    " ZIP RISK SCANNER",
    " CHEMICAL INTEL",
    " WATER & WELLS",
    " County RISK MAP"
])

# ----------- TAB 1: ZIP RISK SCANNER -----------
with tab1:
    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
    st.title("NC Personal Risk Scanner")

    zip_input = st.text_input(
        "ENTER NC ZIP CODE",
        placeholder="e.g. 28401",
        max_chars=5
    )

    if zip_input:
        # --- Risk lookup logic (UNCHANGED) ---
        if zip_input in nc_hotspots:
            score = nc_hotspots[zip_input]
            info_text = f""
        else:
            if nc_hotspots:
                nearest_zip = min(
                    nc_hotspots.keys(),
                    key=lambda z: abs(int(z[:3]) - int(zip_input[:3]))
                )
                score = nc_hotspots[nearest_zip]
                info_text = (
                    f"Extrapolated from nearest ZIP ({nearest_zip}) "
                    f"showing most likely {score} risk."
                )
            else:
                score = "No Data"
                info_text = "No PFAS data available."

        # --- Color mapping ---
        color = "#ff4b4b" if score == "High" else "#ffaa00" if score == "Medium" else "#00ffcc"

        # --- Actionable guidance ---
        if score == "High":
            action_text = '''
            <ul style="text-align:left; font-size:18px; color:white;">
                <li><b>Do not</b> drink unfiltered tap water.</li>
                <li>Use an NSF-certified PFAS filter (RO or activated carbon).</li>
                <li>Request local water utility test results.</li>
                <li>Consider bottled water for infants & pregnant individuals.</li>
                <li>Support local PFAS cleanup or testing initiatives.</li>
            </ul>
            '''
        elif score == "Medium":
            action_text = '''
            <ul style="text-align:left; font-size:18px; color:white;">
                <li>Install a PFAS-reducing water filter.</li>
                <li>Limit tap water use for cooking and drinking.</li>
                <li>Check for updated testing from your water provider.</li>
                <li>Consult with a health professional for personalized advice.</li>
            </ul>
            '''
        else: # Low or No Data
            action_text = '''
            <ul style="text-align:left; font-size:18px; color:white;">
                <li>Stay informed about local water quality reports.</li>
                <li>Consider basic filtration for peace of mind.</li>
                <li>Advocate for regular and comprehensive water testing.</li>
            </ul>
            '''

        st.markdown(f'''
            <div style="text-align: center; border: 1px solid {color}; border-radius: 20px; padding: 30px; background: rgba(0,0,0,0.4);">
                <h1 style="font-size: 85px; color:{color}; margin:0;">{score}</h1>
                <h3 style="margin-top:0;">RISK LEVEL</h3>
                <p style="margin-top:5px;">{info_text}</p>
                <hr style="border-top: 1px solid rgba(255,255,255,0.2); margin: 20px 0;">
                <h3 style="margin-bottom:10px;">RECOMMENDED ACTIONS</h3>
                {action_text}
            </div>
        ''', unsafe_allow_html=True)

    st.markdown('</div>', unsafe_allow_html=True)

# ----------- TAB 2: CHEMICAL INTEL -----------
with tab2:
    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
    st.header("Compound Analysis")
    comp_target = st.selectbox("Select Target", ["GenX", "PFOA", "PFOS"])
    stats = {"GenX": [95, "10ppt", "+12%"], "PFOA": [88, "4ppt", "-2%"], "PFOS": [82, "4ppt", "-5%"]}
    c1, c2, c3 = st.columns(3)
    c1.metric("Hazard Index", f"{stats[comp_target][0]}%", "+2.1%")
    c2.metric("EPA Threshold", stats[comp_target][1], delta="Strict")
    c3.metric("5Y Projection", stats[comp_target][2], delta_color="inverse")
    fig = px.density_heatmap(pd.DataFrame(np.random.randn(20, 2), columns=['x', 'y']), x='x', y='y', color_continuous_scale='Bluered')
    fig.update_layout(paper_bgcolor='rgba(0,0,0,0)', font_color='white', plot_bgcolor='rgba(0,0,0,0)', height=350)
    st.plotly_chart(fig, use_container_width=True)
    st.markdown('</div>', unsafe_allow_html=True)

# ----------- TAB 3: WATER & WELLS -----------
with tab3:
    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
    st.header(" NC Well Safety Hub (2026)")
    col_a, col_b = st.columns(2)
    with col_a:
        st.subheader("Filtration Efficacy")
        tech_data = pd.DataFrame({"Method": ["Reverse Osmosis", "Activated Carbon", "Ion Exchange", "Standard Pitcher"], "Removal %": [99.5,75.0,92.0,45.0]})
        st.bar_chart(tech_data.set_index("Method"))
    with col_b:
        st.subheader("Free Testing Zones")
        st.info("The NC DEQ requires Chemours to provide free testing for private wells in:")
        st.markdown("- **Cumberland & Bladen**\n- **Sampson & Robeson**\n- **New Hanover, Brunswick, Pender**")
        st.warning(" Call **(910) 678-1101** to request sampling.")
    st.markdown("---")
    st.subheader("The 'Deep Well' Strategy")
    st.write("Recent 2025-26 studies suggest that **Bedrock Wells** may bypass the GenX plume currently affecting the shallow surficial aquifer.")
    st.markdown('<div style="background: rgba(0, 180, 216, 0.1); border-left: 5px solid #00b4d8; padding: 15px;"><b>Action Plan:</b> If you are on a private well in the Cape Fear basin, DO NOT boil your water. Install a certified under-sink RO system immediately.</div>', unsafe_allow_html=True)
    st.markdown('</div>', unsafe_allow_html=True)

# ------------ Tab 4: County Map ------------------
with tab4:
    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
    st.header("NC PFAS County-Level Risk Map")

    # Load the pre-processed data
    try:
        df_county_full_dashboard = pd.read_csv('pfas_nc_clean_proximity_interpolated.csv')
        st.success("Loaded county-level PFAS data for mapping.")
    except FileNotFoundError:
        st.error("County-level PFAS data file not found (pfas_nc_clean_proximity_interpolated.csv). Map cannot be displayed.")
        df_county_full_dashboard = pd.DataFrame() # Empty DataFrame to prevent further errors

    if not df_county_full_dashboard.empty:
        # Re-create nc_geojson needed for plotly choropleth
        geojson_url = 'https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json'
        try:
            response = requests.get(geojson_url, timeout=5) # Add timeout
            us_counties_geojson = response.json()
            nc_geojson_features = [f for f in us_counties_geojson['features'] if f['id'][:2] == '37']
            nc_geojson = {"type": "FeatureCollection", "features": nc_geojson_features}
        except requests.exceptions.Timeout:
            st.error("Request to load GeoJSON timed out. Map may not display correctly.")
            nc_geojson = None
        except requests.exceptions.RequestException as e:
            st.error(f"Error downloading GeoJSON: {e}. Map may not display correctly.")
            nc_geojson = None

        if nc_geojson:
            fig = px.choropleth(df_county_full_dashboard,
                                geojson=nc_geojson,
                                locations='fips',
                                featureidkey="id",
                                color='overall_risk',
                                color_discrete_map={'Low': 'green', 'Medium': 'yellow', 'High': 'red', 'No Data': 'lightgray'},
                                scope='usa',
                                hover_name='county',
                                hover_data={'overall_risk': True, 'health_info': True, 'is_interpolated': True, 'fips': False},
                                title='NC PFAS Risk by County (With Proximity-Based Interpolation)'
                               )
            fig.update_geos(fitbounds='locations', visible=False)
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("Skipping map generation due to GeoJSON loading issues.")
    st.markdown('</div>', unsafe_allow_html=True)

"""
# ------------------ SAVE DASHBOARD ------------------
with open("colab_dashboard.py", "w", encoding="utf-8") as f:
    f.write(dashboard_code)

# ------------------ REBOOT SERVER ------------------
ngrok.kill()
os.system("pkill -9 ngrok")
os.system("pkill -9 streamlit")
threading.Thread(target=lambda: os.system("streamlit run colab_dashboard.py --server.port 8501 --server.headless true"), daemon=True).start()

print(" DEPLOYING NC PFAS INTELLIGENCE DASHBOARD...")
time.sleep(12)

try:
    url = ngrok.connect(8501, bind_tls=True)
    print(f"\n SYSTEM ONLINE\n LINK: {url.public_url}")
except Exception as e:
    print(f"Error: {e}")

